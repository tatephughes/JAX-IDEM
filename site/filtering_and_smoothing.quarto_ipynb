{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Filtering in JAX-IDEM\"\n",
        "author: \"Evan Tate Paterson Hughes\"\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "    toc: true\n",
        "    inclue-in-header: header.html\n",
        "    mathjax: \n",
        "      extensions: [\"breqn\", \"bm\", \"ams\"]\n",
        "jupyter: python3\n",
        "bibliography: Bibliography.bib\n",
        "---\n",
        "\n",
        "\n",
        "::: {.content-visible unless-format=\"pdf\"}\n",
        "\n",
        "[Index](../index.html)\n",
        "\n",
        ":::\n",
        "\n",
        "\n",
        "# A Simple Example\n",
        "\n",
        "Although the project is primarily for Integro-Difference equation models, the file ```filter_and_smoother_functions``` provides functions applicable for any discrete dynamical system.\n",
        "This page provides a very simple example to test the kalman filter, the information filter, and fitting with the corresponding likelihoods.\n",
        "\n",
        "## The simple model\n",
        "\n",
        "Consider the simple system, for $t=1,\\dots,T$\n",
        "\n",
        "$$\\begin{split}\n",
        "\\vec\\alpha_{t+1} &= M\\vec\\alpha_t + \\vec\\eta_t,\\\\\n",
        "\\end{split}\n",
        "$$ {#eq-system}\n",
        "\n",
        "where $\\alpha_0 = (1,1)^\\intercal$ and\n",
        "\n",
        "$$\\begin{split}\n",
        "M = \\left[\\begin{matrix}\n",
        "\t\\cos(0.3) & -\\sin(0.3)\\\\\n",
        "\t\\sin(0.3) & \\sin(0.3)\n",
        "\\end{matrix}\\right].\n",
        "\\end{split}\n",
        "$$ {#eq-propmat}\n",
        "\n",
        "The error terms are mutually independant and have variances $\\sigma^{2}_\\epsilon=0.02$ and $\\sigma^{2}_{\\eta}=0.03$\n",
        "and $\\vec z_t$ are transformed linear 'observations' of $\\vec\\alpha$\n",
        "\n",
        "$$\\begin{split}\n",
        "\\vec z_t &= \\Phi \\vec\\alpha_t + \\vec\\epsilon_t,\\\\\n",
        "\\Phi &= \\left[\\begin{matrix}\n",
        "1   & 0  \\\\\n",
        "0.6 & 0.4\\\\\n",
        "0.4 & 0.6\n",
        "\\end{matrix}\\right]\n",
        "\\end{split}.\n",
        "$$ {#eq-obs}\n",
        "\n",
        "The process, $\\alpha$, simply spins in a circle with some noise.\n",
        "Lets simulate from this system;\n"
      ],
      "id": "8fd8aff5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| output: false\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../src/jaxidem'))\n",
        "\n",
        "import jax.random as rand\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import filter_smoother_functions as fsf\n",
        "import testfuncs\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import plotly.graph_objs as go\n",
        "import pandas as pd\n",
        "\n",
        "jax.config.update('jax_enable_x64', True)"
      ],
      "id": "0f99680b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The true underlying system"
      },
      "source": [
        "#| echo: true\n",
        "#| output: true\n",
        "#| label: fig-truth\n",
        "\n",
        "key = jax.random.PRNGKey(1)\n",
        "\n",
        "\n",
        "alpha_0 = jnp.ones(2)  # 2D, easily plottable\n",
        "M = jnp.array([[jnp.cos(0.3), -jnp.sin(0.3)],\n",
        "              [jnp.sin(0.3), jnp.cos(0.3)]])  # spinny\n",
        "\n",
        "alphas = [alpha_0]\n",
        "zs = []\n",
        "\n",
        "T = 50\n",
        "keys = rand.split(key, T*2)\n",
        "\n",
        "sigma2_eta = 0.001\n",
        "Sigma_eta = sigma2_eta*jnp.eye(2)\n",
        "chol_s_eta = jax.scipy.linalg.cholesky(Sigma_eta, lower=True)\n",
        "sigma2_eps = 0.01\n",
        "Sigma_eps = sigma2_eps*jnp.eye(3)\n",
        "chol_s_eps = jax.scipy.linalg.cholesky(Sigma_eps, lower=True)\n",
        "PHI = jnp.array([[1, 0], [0.6, 0.4], [0.4, 0.6]])\n",
        "\n",
        "for i in range(T):\n",
        "    alphas.append(M@alphas[i] + chol_s_eta @\n",
        "                  rand.normal(keys[2*i], shape=(2,)))\n",
        "    zs.append(PHI @ alphas[i+1] + chol_s_eps @\n",
        "              rand.normal(keys[2*i+1], shape=(3,)))\n",
        "\n",
        "alphas_df = pd.DataFrame(alphas, columns = [\"x\", \"y\"])\n",
        "zs_df = pd.DataFrame(zs, columns = [\"x\", \"y\", \"z\"])\n",
        "\n",
        "\n",
        "alphas = jnp.array(alphas)\n",
        "zs = jnp.array(zs)\n",
        "\n",
        "    \n",
        "fig1 = px.line(alphas_df, x='x', y='y', height=200)\n",
        "fig1.update_layout(xaxis=dict(scaleanchor=\"y\", scaleratio=1, title='X Axis'), yaxis=dict(scaleanchor=\"x\", scaleratio=1, title='Y Axis'))"
      ],
      "id": "fig-truth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The 3D observations"
      },
      "source": [
        "#| label: fig-obs\n",
        "\n",
        "fig2 = go.Figure(data=[go.Scatter3d(\n",
        "    x=zs_df['x'],\n",
        "    y=zs_df['y'],\n",
        "    z=zs_df['z'],\n",
        "    mode='markers',\n",
        "    marker=dict(\n",
        "        symbol='cross',  # Change marker to cross\n",
        "        size=5           # Adjust marker size\n",
        "    )\n",
        ")])\n",
        "\n",
        "fig2.update_layout(height=200)\n",
        "    \n",
        "fig2.show()"
      ],
      "id": "fig-obs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see how the process is an odd random spiral, and the observations are skewed noisy observations of this in 3D space\n",
        "\n",
        "With filtering, we aim to recover the process {fig-truth} from the observations {fig-obs}. \n",
        "We do this with two 'forms' of the filter, which should be equivalent.\n",
        "\n",
        "# Kalman filter\n"
      ],
      "id": "463e26f3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The (Kalman) filtered means"
      },
      "source": [
        "#| label: fig-kalman\n",
        "    \n",
        "m_0 = jnp.zeros(2)\n",
        "P_0 = 100*jnp.eye(2)\n",
        "\n",
        "# Since we have independant errors, we can use the faster kalman_filter_indep.\n",
        "    \n",
        "ll, ms, Ps, _, _, _ = fsf.kalman_filter_indep(m_0,\n",
        "                                              P_0,\n",
        "                                              M,\n",
        "                                              PHI,\n",
        "                                              sigma2_eta,\n",
        "                                              sigma2_eps,\n",
        "                                              zs.T,\n",
        "                                              likelihood='full'\n",
        "    )\n",
        "\n",
        "#print(ms)\n",
        "    \n",
        "ms_df = pd.DataFrame(list(ms), columns = [\"x\", \"y\"])\n",
        "\n",
        "combined_df = pd.concat([alphas_df.assign(line='True Process'), ms_df.assign(line='Filtered Process Means')])\n",
        "\n",
        "# Creating the line plot with custom colors\n",
        "fig3 = px.line(combined_df, x='x', y='y', color='line',\n",
        "               color_discrete_sequence=['blue', 'red'], height=200)  # Specify colors here\n",
        "\n",
        "fig3.update_layout(xaxis=dict(scaleanchor=\"y\", scaleratio=1, title='X Axis'), yaxis=dict(scaleanchor=\"x\", scaleratio=1, title='Y Axis'))\n",
        "# Show the plot\n",
        "fig3.show()"
      ],
      "id": "fig-kalman",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Information Filter\n",
        "\n",
        "Similarily, we can apply the information filter.\n",
        "Since the information filter function has support for time varying observation shapes, there is a little more work to do.\n"
      ],
      "id": "9b1dbf69"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The (information) filtered means"
      },
      "source": [
        "#| label: fig-information\n",
        "\n",
        "Q_0 = 0.01 * jnp.eye(2) \n",
        "nu_0 = jnp.zeros(2)\n",
        "\n",
        "PHI_tuple = tuple([PHI for _ in range(T)])\n",
        "zs_tuple = tuple(zs)\n",
        "\n",
        "ll2, nus, Qs,_ ,_  = fsf.information_filter_indep_experimental(nu_0,\n",
        "                                                 Q_0,\n",
        "                                                 M,\n",
        "                                                 PHI_tuple,\n",
        "                                                 sigma2_eta,\n",
        "                                                 sigma2_eps,\n",
        "                                                 zs_tuple,\n",
        "                                                 likelihood='full'\n",
        "    )\n",
        "\n",
        "ms2 = jnp.linalg.solve(Qs, nus[..., None]).squeeze(-1)\n",
        "\n",
        "ms2_df = pd.DataFrame(list(ms2), columns = [\"x\", \"y\"])\n",
        "\n",
        "combined_df_2 = pd.concat([alphas_df.assign(line='True Process'), ms2_df.assign(line='Filtered Process Means')])\n",
        "\n",
        "# Creating the line plot with custom colors\n",
        "fig4 = px.line(combined_df_2, x='x', y='y', color='line',\n",
        "               color_discrete_sequence=['blue', 'green'], height=200)  # Specify colors here\n",
        "\n",
        "fig4.update_layout(xaxis=dict(scaleanchor=\"y\", scaleratio=1, title='X Axis'), yaxis=dict(scaleanchor=\"x\", scaleratio=1, title='Y Axis'))\n",
        "# Show the plot\n",
        "fig4.show()"
      ],
      "id": "fig-information",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can clearly see that the green and red lines are the same; if plotted over eachother, they overlap. \n",
        "They only differ slightly due to numerical error.\n",
        "\n",
        "We still need to look at the log-likelihoods that were outputted;\n"
      ],
      "id": "8c5a8e48"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(ll)\n",
        "print(ll2)"
      ],
      "id": "6b02435f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These values are very different _but that might be ok_. \n",
        "The log-likehoods are only correct up to a additive constant, and the two likelihoods are based off the distirbutions of different variables; the first on the direct residuals, the second on an 'information' transformed version.\n",
        "The key is that both should increase with how accurate the model is, so any fitting algorithm should give the same results for both.\n",
        "\n",
        "# Fitting\n",
        "\n",
        "Let's 'forget' some of the details of the original model; the propegation matrix $M$ and the variances $\\sigma^2_\\epsilon$ and $\\sigma^2_\\eta$ (though we keep the assumption that everything is independant)\n"
      ],
      "id": "2d4e58de"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The (Kalman) fitted and filtered means"
      },
      "source": [
        "#| label: fig-kalman-fitted\n",
        "\n",
        "# initial guesses\n",
        "\n",
        "def objective_kalman(params):\n",
        "    M = params['M']\n",
        "    sigma2_eps = jnp.exp(params['log_sigma2_eps'])\n",
        "    sigma2_eta = jnp.exp(params['log_sigma2_eta'])\n",
        "\n",
        "    Sigma_eta = sigma2_eta * jnp.eye(2)\n",
        "    Sigma_eps = sigma2_eps * jnp.eye(3)\n",
        "\n",
        "    ll, ms, Ps, _, _, _ = fsf.kalman_filter(m_0,\n",
        "                                            P_0,\n",
        "                                            M,\n",
        "                                            PHI,\n",
        "                                            Sigma_eta,\n",
        "                                            Sigma_eps,\n",
        "                                            zs.T,\n",
        "                                            likelihood=\"full\")\n",
        "    return -ll\n",
        "\n",
        "objk_grad = jax.grad(objective_kalman)\n",
        "             \n",
        "import optax\n",
        "\n",
        "# initial guesses\n",
        "param0 = {\"M\": jnp.eye(2),\n",
        "          \"log_sigma2_eps\": jnp.log(jnp.array(0.01)),\n",
        "          \"log_sigma2_eta\": jnp.log(jnp.array(0.01))}\n",
        "start_learning_rate = 1e-1\n",
        "optimizer = optax.adam(start_learning_rate)\n",
        "param_ad = param0\n",
        "opt_state = optimizer.init(param_ad)\n",
        "import time\n",
        "start_time = time.time()\n",
        "                                   \n",
        "for i in range(50):\n",
        "    grad = objk_grad(param_ad)\n",
        "    updates, opt_state = optimizer.update(grad, opt_state)\n",
        "    param_ad = optax.apply_updates(param_ad, updates)\n",
        "    nll = objective_kalman(param_ad)\n",
        "#    print(nll)\n",
        "\n",
        "ll, ms3, Ps, _, _, _ = fsf.kalman_filter(m_0,\n",
        "                                         P_0,\n",
        "                                         param_ad['M'],\n",
        "                                         PHI,\n",
        "                                         jnp.exp(param_ad['log_sigma2_eta'])*jnp.eye(2),\n",
        "                                         jnp.exp(param_ad['log_sigma2_eps'])*jnp.eye(3),\n",
        "                                         zs.T,)\n",
        "end_time = time.time()\n",
        "\n",
        "print(f\"Time Elapsed is {end_time - start_time}\")\n",
        "print(param_ad)\n",
        "print(\"true M is \", M)\n",
        "\n",
        "ms3_df = pd.DataFrame(list(ms3), columns = [\"x\", \"y\"])\n",
        "\n",
        "combined_df = pd.concat([alphas_df.assign(line='True Process'), ms3_df.assign(line='Filtered Process Means')])\n",
        "\n",
        "# Creating the line plot with custom colors\n",
        "fig4 = px.line(combined_df, x='x', y='y', color='line',\n",
        "               color_discrete_sequence=['blue', 'red'], height=200)  # Specify colors here\n",
        "\n",
        "fig4.update_layout(xaxis=dict(scaleanchor=\"y\", scaleratio=1, title='X Axis'), yaxis=dict(scaleanchor=\"x\", scaleratio=1, title='Y Axis'))\n",
        "# Show the plot\n",
        "fig4.show()"
      ],
      "id": "fig-kalman-fitted",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These results are great.\n",
        "Lets confirm that the information filter is also working, using the same method\n"
      ],
      "id": "e560978e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig-caption": "The (information) fitted and filtered means"
      },
      "source": [
        "#| eval: true\n",
        "#| label: fig-information-fitted\n",
        "\n",
        "@jax.jit\n",
        "def objective_info(params):\n",
        "    M = params['M']\n",
        "    sigma2_eps = jnp.exp(params['log_sigma2_eps'])\n",
        "    sigma2_eta = jnp.exp(params['log_sigma2_eta'])\n",
        "\n",
        "    ll, _, _, _, _ = fsf.information_filter_indep_experimental(nu_0,\n",
        "                                      Q_0,\n",
        "                                      M,\n",
        "                                      PHI_tuple,\n",
        "                                      sigma2_eta,\n",
        "                                      sigma2_eps,\n",
        "                                      zs_tuple,\n",
        "                                      likelihood=\"full\")\n",
        "    return -ll\n",
        "\n",
        "obji_grad = jax.grad(objective_info)\n",
        "\n",
        "# initial guesses\n",
        "param0 = {\"M\": jnp.eye(2),\n",
        "          \"log_sigma2_eps\": jnp.log(jnp.array(0.01)),\n",
        "          \"log_sigma2_eta\": jnp.log(jnp.array(0.01))}\n",
        "start_learning_rate = 1e-1\n",
        "optimizer = optax.adam(start_learning_rate)\n",
        "param_ad = param0\n",
        "opt_state = optimizer.init(param_ad)\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(50):\n",
        "    grad = obji_grad(param_ad)\n",
        "    updates, opt_state = optimizer.update(grad, opt_state)\n",
        "    param_ad = optax.apply_updates(param_ad, updates)\n",
        "    nll = objective_info(param_ad)\n",
        "    #print(nll)\n",
        "\n",
        "ll, nus, Qs, _, _ = fsf.information_filter_indep(nu_0,\n",
        "                                     Q_0,\n",
        "                                     param_ad['M'],\n",
        "                                     PHI_tuple,\n",
        "                                     jnp.exp(param_ad['log_sigma2_eta']),\n",
        "                                     jnp.exp(param_ad['log_sigma2_eps']),\n",
        "                                     zs_tuple,)\n",
        "\n",
        "ms4 = jnp.linalg.solve(Qs, nus[..., None]).squeeze(-1)\n",
        "                                                                     \n",
        "#ll, nus, Qs = fsf.information_filter_indep(nu_0,\n",
        "#                                           P_0,\n",
        "#                                           param_ad['M'],\n",
        "#                                           PHI_tuple,\n",
        "#                                           param_ad['sigma2_eta'],\n",
        "#                                           param_ad['sigma2_eps'],\n",
        "#                                           zs_tuple,)\n",
        "\n",
        "                                                                \n",
        "end_time = time.time()\n",
        "                                                                                         \n",
        "print(f\"Time Elapsed is {end_time - start_time}\")\n",
        "print(param_ad)\n",
        "print(\"true M is \", M)\n",
        "\n",
        "ms4_df = pd.DataFrame(list(ms4), columns = [\"x\", \"y\"])\n",
        "\n",
        "combined_df = pd.concat([alphas_df.assign(line='True Process'), ms4_df.assign(line='Filtered Process Means')])\n",
        "\n",
        "# Creating the line plot with custom colors\n",
        "fig5 = px.line(combined_df, x='x', y='y', color='line',\n",
        "               color_discrete_sequence=['blue', 'green'], height=200)  # Specify colors here\n",
        "\n",
        "fig5.update_layout(xaxis=dict(scaleanchor=\"y\", scaleratio=1, title='X Axis'), yaxis=dict(scaleanchor=\"x\", scaleratio=1, title='Y Axis'))\n",
        "# Show the plot\n",
        "fig5.show()"
      ],
      "id": "fig-information-fitted",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/home/tate/Projects/JAX-IDEM/.venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
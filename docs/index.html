<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Evan Tate Paterson Hughes" />
  <title>Integro-Difference Equation Model</title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    svg {
      height: auto;
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Integro-Difference Equation Model</h1>
<p class="author">Evan Tate Paterson Hughes</p>
</header>
<div class="BOILERPLATE drawer">

</div>
<hr />
<p>[VERY UNFINISHED. PLEASE IGNORE.]</p>
<hr />
<h1 id="introduction">Introduction</h1>
<p>As common and widespread as the problem is, spatio-temporal modelling
still presents a great deal of difficulty. Inherently, Spatio-Temporal
datasets are almost always high-dimensional, and repeated observations
are usually not possible.</p>
<p>Traditionally, a descriptive approach has been made to model such
systems. This means we are most concerned with modelling the moments
(means, covariances) of the process. More recently, a dynamical approach
has been suggested by many authors [citation needed]. Here, we use
knowledge of underlying dynamics to drive the model.</p>
<p>One such model is the Integro-Difference Equation Model (IDEM),
which, in essence, is a state-space model, which models diffusion and
advection. In order to do computations, the system is discretized using
basis function expansions.</p>
<p>The following IDEM model is considered;</p>
<p>Where <span
class="math inline"><em>η</em><sub><em>t</em></sub>(<em>s⃗</em>)</span>
is a small scale variation with no temporal dynamics (Cressie and Wikle
call this a `spatially descriptive' component.), <span
class="math inline"><em>X⃗</em>(<em>s⃗</em>)</span> are spatially varying
covariates, <span class="math inline"><em>Z</em></span> is observed
data, <span class="math inline"><em>Y</em></span> is the unobserved
dynamical process, and <span class="math inline"><em>κ</em></span> is
the driving 'kernel' function.</p>
<p>This seems like a reasonable model for the process's diffusion and
advection in a spatially continuous way. Each state is a continuous
weighted integral (sum) of the previous state. The form of <span
class="math inline"><em>κ</em></span> allows us to make use of some of
the dynamics of the system; in many geological settings we most likely
follow Tobler's law in some sense to model diffusion, with weights
depending of the direction of <span
class="math inline"><em>s⃗</em> − <em>r⃗</em></span> giving us advection,
or movement, of the process.</p>
<p>Further, we assume that <span
class="math inline"><em>ϵ</em><sub><em>t</em></sub>(<em>s⃗</em>)</span>
and <span
class="math inline"><em>η</em><sub><em>t</em></sub>(<em>s⃗</em>)</span>
are uncorrelated with each other, and uncorrelated in time.</p>
<p>( Re-do the below to not assume any particular decomposition of <span
class="math inline"><em>κ</em></span>. There is also some older notation
here, I need to change this to be more in-line with the actual code.
)</p>
<p>We decompose the process and the kernel as follows <span
class="citation" data-cites="dewar2008data">[cite:roughly following
@dewar2008data]</span>;</p>
<p>where <span
class="math inline">{<em>ψ</em><sub><em>i</em></sub>}<sub><em>i</em> ∈ ℕ</sub></span>
and <span
class="math inline">{<em>ϕ</em><sub><em>j</em></sub>}<sub><em>j</em> ∈ ℕ</sub></span>
are complete, linearly independent sets of basis functions. If we have a
homogeneous kernel <span class="citation"
data-cites="wikle1999dimension">[cite:as in @wikle1999dimension]</span>,
we could use the same set of basis functions for the expansion of <span
class="math inline"><em>m</em></span> and <span
class="math inline"><em>Y</em></span>. <span
class="math inline"><em>α</em><sub><em>i</em>, <em>t</em></sub></span>
and <span
class="math inline"><em>β</em><sub><em>i</em>, <em>t</em></sub></span>
are unknown sequences.</p>
<p>We assume that and can be decomposed into <span
class="math inline"><em>I</em></span> and <span
class="math inline"><em>J</em></span> dominant components respectively,
and truncate these sums and write them in vector form;</p>
<p>where <span
class="math inline"><em>ψ⃗</em><sub><em>I</em></sub>(<em>s⃗</em>,<em>r⃗</em>) = (<em>ψ</em><sub>1</sub>(<em>s⃗</em>,<em>r⃗</em>),…,<em>ψ</em><sub><em>I</em></sub>(<em>s⃗</em>,<em>r⃗</em>))<sup>⊺</sup></span>
and <span
class="math inline"><em>ϕ⃗</em><sub><em>J</em></sub>(<em>s⃗</em>) = (<em>ϕ</em><sub>1</sub>(<em>s⃗</em>),…,<em>ϕ</em><sub><em>J</em></sub>(<em>s⃗</em>))<sup>⊺</sup></span>.
For brevity, we write <span
class="math inline"><em>m</em> = <em>m</em><sub><em>I</em></sub></span>
and <span
class="math inline"><em>Y</em> = <em>Y</em><sub><em>J</em></sub></span>
in the following.</p>
<div class="lemma">
<p>We assume that the small-scale variation <span
class="math inline"><em>ν⃗</em><sub><em>t</em></sub>(<em>s⃗</em>)</span>
in is Gaussian with zero mean and covariance defined by</p>
<p>Then, the integral</p>
<p>is also Gaussian with zero mean and covariance</p>
</div>
<div class="proof">
<p>We have that is a linear combination of Gaussian <span
class="math inline"><em>ν</em><sub><em>t</em></sub>(<em>s⃗</em>)</span>,
therefore it is itself Gaussian. Showing the two moments is then easy.
With expectations and covariances taken with respect to time,</p>
</div>
<p>Continuing to follow Dewar et al. with some generalisation, we define
the following matrices;</p>
<p>Using these, we can finally return to a familiar state-space
form.</p>
<div class="theorem">
<p>We have that <span class="math inline"><em>β⃗</em>(<em>t</em>)</span>
evolves by the state-space equation</p>
<p>where <span
class="math inline"><em>η</em><sub><em>t</em></sub></span> is Gaussian
with covariance <span class="math inline">$\sigma^2(\mat
\Psi^{(Z)})^{-1}$</span>, and <span class="math inline">$\mat M_t =
(\mat\Psi^{(Z)})^{-1}\mat\Psi^{(\alpha)}_t$</span>.</p>
<p>Furthermore, we then recall that we assume (ignoring approximations)
that <span
class="math inline"><em>Y</em>(<em>s⃗</em>;<em>t</em>) = <em>ϕ⃗</em>(<em>s⃗</em>)<sup>⊺</sup><em>β⃗</em>(<em>t</em>)</span>.
So, fixing stations <span
class="math inline">{<em>s⃗</em><sub>1</sub>, …, <em>s⃗</em><sub><em>n</em></sub>}</span>
and setting <span class="math inline">$\mat X = [\vec\phi(\vec s_1),
\dots, \vec \phi(\vec s_n)]^{\intercal}$</span>, we return to a system
of the form .</p>
</div>
<div class="proof">
<p>Expanding with and ,</p>
<p>Now we multiply the left hand side by <span
class="math inline"><em>ϕ⃗</em>(<em>s⃗</em>)</span> and integrate over
<span class="math inline"><em>s⃗</em></span>,</p>
<p>where we used Lemma . We then arrive at by multiplying the left hand
sides by <span class="math inline">$(\mat\Psi^{(Z)})^{-1}$</span>,
writing <span class="math inline">$\vec\eta_t:=
(\mat\Psi^{(Z)})^{-1}\vec\omega_t$</span>. Finding the covariance of
<span class="math inline"><em>η⃗</em><sub><em>t</em></sub></span> follows
directly from Lemma .</p>
<p>Once the stations are fixed, we can write <span
class="math inline"><em>Y⃗</em>(<em>t</em>) = (<em>Y</em>(<em>s⃗</em><sub>1</sub>;<em>t</em>),…,<em>Y</em>(<em>s⃗</em><sub><em>n</em></sub>;<em>t</em>))</span>
and <span
class="math inline"><em>Z⃗</em>(<em>t</em>) = (<em>Z</em>(<em>s⃗</em><sub>1</sub>;<em>t</em>),…,<em>Z</em>(<em>s⃗</em><sub><em>n</em></sub>;<em>t</em>))</span>,
then we get a system of the form .</p>
</div>
</body>
</html>

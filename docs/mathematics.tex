% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother


\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

<script>
window.MathJax = {
  loader: {
    load: ['[tex]/upgreek', '[tex]/boldsymbol', '[tex]/physics', '[tex]/breqn'
  },
  tex: {
    packages: {
      '[+]': ['upgreek', 'boldsymbol', 'physics', 'breqn']
    }
  }
};
</script>
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Integro-Difference Equation Models},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{Integro-Difference Equation Models}
\author{}
\date{}

\begin{document}
\maketitle


\href{./index.html}{Index}

\DeclareMathOperator{\var}{\mathbb{V}\mathrm{ar}}
\DeclareMathOperator{\cov}{\mathbb{C}\mathrm{ov}}
\renewcommand*{\vec}[1]{\boldsymbol{\mathbf{#1}}}

\section{Descriptive and Dynamic
Modelling}\label{descriptive-and-dynamic-modelling}

As common and widespread as the problem is, spatio-temporal modelling
still presents a great deal of difficulty. Inherently, Spatio-Temporal
datasets are almost always high-dimensional, and repeated observations
are usually not possible.

Traditionally, a descriptive approach has been made to model such
systems. This means we are most concerned with modelling the moments
(means, covariances) of the process. More recently, a dynamical approach
has been suggested by many authors {[}citation needed{]}. Here, we use
knowledge of underlying dynamics to drive the model.

One such model is the Integro-Difference Equation Model (IDEM), which,
in essence, is a state-space model, which models diffusion and
advection. In order to do computations, the system is discretized using
basis function expansions.

The following model is considered;

\begin{equation}\phantomsection\label{eq-IDEM}{
\begin{split}
Z(\boldsymbol s;t) &= Y(\boldsymbol s;t) + \boldsymbol X(\boldsymbol s)^{\intercal}\boldsymbol \beta + \epsilon_t(\boldsymbol s)\\
Y(\boldsymbol s;t+1) &= \int_{\mathcal D_s} \kappa(s,r) Y(r;t) d\boldsymbol r + \omega_t(\boldsymbol s). 
\end{split}
}\end{equation}

Where \(\omega_t(\boldsymbol s)\sim \mathcal N(0, \Sigma_\omega)\) is a
small scale variation with no temporal dynamics (Cressie and Wikle 2015
call this a `spatially descriptive' component),
\(\boldsymbol X(\boldsymbol s)\) are spatially varying covariates, \(Z\)
is observed data, \(Y\) is the unobserved dynamic process, \(\kappa\) is
the driving `kernel' function, and
\(\epsilon_t\sim \mathcal N(0, \Sigma_\epsilon)\) is a white noise
`measurement error' term.

\section{Process Decomposition}\label{process-decomposition}

In order to work with the process, we likely want to consider the
spectral decomposition of it. That is, choose a complete class of
spatial spectral basis functions, \(\phi_i(\boldsymbol s)\), and
decompose;

\begin{equation}\phantomsection\label{eq-processdecomp}{
Y(\boldsymbol s;t) \approx \sum_{i=1}^{r} \alpha_{i,t} \phi_i(\boldsymbol s).\label{}
}\end{equation}

where we truncate the expansion at some \(r\in\mathbb N\). Notice that
we can write this in vector/matrix form. Discretising the spatial domain
into \(n\) points \(\{\boldsymbol s_i\in \mathcal D_s, i=1,\dots,n\}\),
and consider times \(t=1,2,\dots, T\), we set

\[
\begin{split}
\boldsymbol Y(t) &= (Y(s_1), Y(s_2),  \dots, Y(s_n))^{\intercal}\\
Y &= (\boldsymbol Y(t=1), \boldsymbol Y(t=2), \dots, \boldsymbol Y(t=T))\\
\boldsymbol \phi(\boldsymbol s) &= (\phi_1(\boldsymbol s), \phi_2(\boldsymbol s), \dots, \phi_r(\boldsymbol s))^{\intercal}\\
 \Phi &= (\boldsymbol \phi(\boldsymbol s_1), \boldsymbol \phi(\boldsymbol s_2), \dots, \boldsymbol \phi(\boldsymbol s_n))\\
\boldsymbol \alpha(t) &= (\alpha_1(t), \alpha_2(t), \dots, \alpha_r(t))^{\intercal}\\
 A &= (\boldsymbol \alpha(t=1), \boldsymbol \alpha(t=2), \dots, \boldsymbol \alpha(t=Y)).
\end{split}
\]

Now, (Equation~\ref{eq-processdecomp}) gives us

\begin{equation}\phantomsection\label{eq-pbvec}{
\begin{split}
Y(\boldsymbol s; t) &= \boldsymbol \phi^{\intercal}(\boldsymbol s) \boldsymbol \alpha(t)\\
\boldsymbol Y(t) &=  \Phi \boldsymbol \alpha(t)\\
 Y &=  \Phi  A
\end{split}
}\end{equation}

We now want to find the equation defining the evolution of the basis
coefficients, \(\boldsymbol \alpha_t\).

\subsubsection{Theorem 1}\label{theorem-1}

Define the Gram matrix;

\begin{equation}\phantomsection\label{eq-gram}{
\Psi := \int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol s) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal d\boldsymbol{\mathbf{s}}
}\end{equation}

Then, the basis coefficients evolve by the equation

\[
\boldsymbol{\mathbf{\alpha}}(t+1) = M \boldsymbol{\mathbf{\alpha}}(t) + \boldsymbol{\mathbf{\eta}}_t,
\]

where
\(M = \Psi^{-1} \int\int \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) \kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}})\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}} d \boldsymbol{\mathbf{s}}\)
and
\(\boldsymbol{\mathbf{\eta}}_t =\Psi^{-1} \int \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\omega_t(s)d\boldsymbol{\mathbf{s}}\).

\paragraph{Proof:}\label{proof}

Adapting from (Dewar, Michael and Scerri, Kenneth and Kadirkamanathan,
Visakan, 2008), write out the process equation,
(Equation~\ref{eq-IDEM}), using the first equation of
(Equation~\ref{eq-pbvec});

\[
Y(\boldsymbol{\mathbf{s}};t+1) = \boldsymbol{\mathbf{\phi}}(\boldsymbol s) \alpha(t+1) = \int_{\mathcal D_s} \kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^{\intercal}\boldsymbol{\mathbf{\alpha}}(t)d\boldsymbol{\mathbf{r}} + \omega_t(\boldsymbol{\mathbf{s}}),
\]

We then multiply both sides by \(\boldsymbol \phi(s)\) and integrate
over \(\boldsymbol s\)

\[
\begin{split}
\int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) d\boldsymbol{\mathbf{s}} \boldsymbol{\mathbf{\alpha}}(t+1) &= \int\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\int \kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}})\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}}  d \boldsymbol{\mathbf{s}}\ \boldsymbol{\mathbf{\alpha}}(t) + \int \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\omega_t(s)d\boldsymbol{\mathbf{s}}\\
\Psi \boldsymbol{\mathbf{\alpha}}(t+1) &= \int\int \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}} d \boldsymbol{\mathbf{s}}\ \boldsymbol{\mathbf{\alpha}}(t) + \int \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\omega_t(s)d\boldsymbol{\mathbf{s}}.
\end{split}
\]

So, finally, pre-multipling by the inverse of the gram matrix,
\(\Psi^{-1}\) (Equation~\ref{eq-gram}), we get the result.

\subsection{Process Noise}\label{process-noise}

We still have to set out what the process noise,
\(\omega_t(\boldsymbol{\mathbf{s}})\), and it's spectral couterpart,
\(\boldsymbol{\mathbf{\eta}}_t\), are. Dewar (Dewar, Scerri, and
Kadirkamanathan 2008) fixes the variance of
\(\omega_t(\boldsymbol{\mathbf{s}})\) to be uniform and uncorrelated
across space and time, with
\(\omega_t(\boldsymbol{\mathbf{s}}) \sim \mathcal N(0,\sigma^2)\) It is
then easily shown that \(\boldsymbol{\mathbf{\eta}}_t\) is also normal,
with
\(\boldsymbol{\mathbf{\eta}}_t \sim \mathcal N(0, \sigma^2\Psi^{-1})\).

However, in practice, we simulate in the spectral domain; that is, if we
want to keep things simple, it would make sense to specify (and fit) the
distribution of \(\boldsymbol{\mathbf{\eta}}_t\), and compute the
variance of \(\omega_t(\boldsymbol{\mathbf{s}})\) if needed. This is
exactly what the IDE package (Zammit-Mangion 2022) in R does, and,
correspondingly, what this JAX project does.

\subsubsection{Lemma 1}\label{lemma-1}

Let \(\boldsymbol{\mathbf{\eta}}_t \sim \mathcal N(0, \Sigma_\eta)\),
and
\(\mathop{\mathrm{\mathbb{C}\mathrm{ov}}}[\boldsymbol{\mathbf{\eta}}_t, \boldsymbol{\mathbf{\eta}}_{t+\tau}] =0\),
\(\forall \tau>0\). Then \(\omega_t(\boldsymbol{\mathbf{s}})\) is also
normally distributed, with covariance

\[
\mathop{\mathrm{\mathbb{C}\mathrm{ov}}}[\omega_t(\boldsymbol{\mathbf{s}}), \omega_{t+\tau}(\boldsymbol{\mathbf{r}})] = \begin{cases}
\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal \Sigma_\eta \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}}) & \text{if }\tau=0\\
0 & \text{else}\\
\end{cases}
\]

\paragraph{Proof:}\label{proof-1}

Normality is clear, since \(\boldsymbol{\mathbf{\eta}}_t\) is a linear
combination of \(\omega_t(\boldsymbol{\mathbf{s}})\) {{[}NOTE: I'm
pretty sure this is true, certainly a linear combination of gaussian is
gaussian, but the converse is true as well right?{]}}.

Consider \(\Psi \boldsymbol{\mathbf{\eta}}_t\). It is clearly normal,
with expectation zero and variance (using (Equation~\ref{eq-gram})),

\begin{equation}\phantomsection\label{eq-var1}{
\begin{split}
\mathop{\mathrm{\mathbb{V}\mathrm{ar}}}[\Psi \boldsymbol{\mathbf{\eta}}_t] &= \Psi \mathop{\mathrm{\mathbb{V}\mathrm{ar}}}[\boldsymbol{\mathbf{\omega}}_t] \Psi^\intercal = \Psi\Sigma_\eta\Psi^\intercal,\\
&= \int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal d\boldsymbol{\mathbf{s}} \  \Sigma_\eta \ \int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}}\\
&=  \int\int_{\mathcal D_s^2} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal \  \Sigma_\eta \  \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}} d\boldsymbol{\mathbf{s}}\\
\end{split}
}\end{equation}

Since it has zero expectation, we also have

\begin{equation}\phantomsection\label{eq-var2}{
\begin{split}
\mathop{\mathrm{\mathbb{V}\mathrm{ar}}}[\Psi\boldsymbol{\mathbf{\eta}}_t] &= \mathbb E[(\Psi\boldsymbol{\mathbf{\eta}}_t) (\Psi\boldsymbol{\mathbf{\eta}}_t)^\intercal] = \mathbb E[\Psi\boldsymbol{\mathbf{\eta}}_t\boldsymbol{\mathbf{\eta}}_t^\intercal\Psi^\intercal]\\
&= \mathbb E \left[ \int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\omega_t(\boldsymbol{\mathbf{s}})d\boldsymbol{\mathbf{s}} \int_{\mathcal D_s} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal \omega_t(\boldsymbol{\mathbf{r}}) d\boldsymbol{\mathbf{r}} \right]\\
&= \int\int_{\mathcal D_s^2} \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})\  \mathbb E[\omega_t(\boldsymbol{\mathbf{s}})\omega_t(\boldsymbol{\mathbf{r}})]\  \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{s}} d \boldsymbol{\mathbf{r}}.
\end{split} 
}\end{equation}

We can see that, comparing (Equation~\ref{eq-var1}) and
(Equation~\ref{eq-var2}), we have

\[
\mathop{\mathrm{\mathbb{C}\mathrm{ov}}}[\omega_t(\boldsymbol{\mathbf{s}}), \omega_t(\boldsymbol{\mathbf{r}})] = \mathbb E[\omega_t(\boldsymbol{\mathbf{s}})\omega_t(\boldsymbol{\mathbf{r}})]= \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal \Sigma_\eta \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}}).
\]

\section{Kernel Decomposition}\label{kernel-decomposition}

There are a few ways to handle the kernel. One of the most obvious is to
expand it out into a spectral decomposition as well;

\[
\kappa \approx \sum_i \beta_i\psi(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}).
\]

This can allow for a wide range of interestingly shaped kernel
functions, but see how these basis functions must now act on
\(\mathbb R^2\times \mathbb R^2\); to get a wide enough space of
possible functions, we would likely need many basis coefficients.

A much simpler approach would be to simply parameterise the kernel
function, to
\(\kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}, \boldsymbol{\mathbf{\theta}}_\kappa)\).
We then establish a simple shape for the kernel (e.g.~Gaussian) and rely
on very few parameters (for example, scale, shape, offsets). The example
kernel used in the program is Gaussian kernel;

\[
\kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}; \boldsymbol{\mathbf{m}}, a, b) = a \exp \left( -\frac{1}{b} \Vert \boldsymbol{\mathbf{s}}- \boldsymbol{\mathbf{r}} +\boldsymbol{\mathbf{m}}\Vert^2 \right)
\]

Of course, this kernel lacks spatial dependance. We can add spatial
variance back in in a nice way by adding dependance on
\(\boldsymbol{\mathbf{s}}\) to the parameters, for example, variyng the
offset term as \(\boldsymbol{\mathbf{m}}(\boldsymbol{\mathbf{s}})\). Of
course, now we are back to having entire functions as parameters, but
taking the spectral decomposition of the parameters we actually want to
be spatially variant seems like a reasonable middle ground (Cressie and
Wikle 2015). The actual parameters of such a spatially-variant kernel
are then the basis coefficients for the expansion of any spatially
variant parameters, as well as any constant parameters.

\section{EM algorithm}\label{em-algorithm}

Firstly, we finish establishing our model, now with the spectral form;

\[
\begin{split}
\boldsymbol{\mathbf{Z}}(t) &= \boldsymbol{\mathbf{Y}}(t) + X \boldsymbol{\mathbf{\beta }}+ \boldsymbol{\mathbf{\epsilon}}_t, \quad t=0,1,\dots, T,\\
Y(\boldsymbol{\mathbf{s}};t) &= \boldsymbol{\mathbf{\alpha}}(t)^\intercal \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}), \quad t = 0,1,\dots, T,\\
\boldsymbol{\mathbf{\alpha}}(t+1) &= M\boldsymbol{\mathbf{\alpha}}(t) + \boldsymbol{\mathbf{\eta}}_t,\quad t = 1,2,\dots, T,\\
M &= \int_{\mathcal D_s}\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) \boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}})^\intercal d\boldsymbol{\mathbf{s}} \int_{\mathcal D_s^2}\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}) \kappa(\boldsymbol{\mathbf{s}}, \boldsymbol{\mathbf{r}}; \boldsymbol{\mathbf{\theta}}_\kappa)\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{r}})^\intercal d\boldsymbol{\mathbf{r}} d \boldsymbol{\mathbf{s}},
\end{split}
\]

where
\(\boldsymbol{\mathbf{Y}}(t) = (Y(\boldsymbol{\mathbf{s}}_{1};t), \dots, Y(\boldsymbol{\mathbf{s}}_{n};t))\)
for stations \(\{\boldsymbol{\mathbf{s}}_{i}\}_{i=1,\dots, n}\).

We can also combine the first two lines to `skip' the process and see
the more traditional LDSTM form;

\begin{equation}\phantomsection\label{eq-ldstm}{
\begin{split}
\boldsymbol{\mathbf{Z}}(t) &= \Phi\boldsymbol{\mathbf{\alpha}}(t) + X\boldsymbol{\mathbf{\beta }}+ \boldsymbol{\mathbf{\epsilon}}_t,\quad &t = 0,1,\dots, T,\\
\boldsymbol{\mathbf{\alpha}}(t+1) &= M\boldsymbol{\mathbf{\alpha}}(t) + \boldsymbol{\mathbf{\eta}}_t,\quad &t = 1,2,\dots, T,\\
\end{split}
}\end{equation}

where
\(\Phi = (\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}_1),\dots,\boldsymbol{\mathbf{\phi}}(\boldsymbol{\mathbf{s}}_n))^\intercal\).
We should also initialise
\(\boldsymbol{\mathbf{\alpha}}(0) \sim \mathcal N^{r}(\boldsymbol{\mathbf{m}}_{0}, \Sigma_{0})\).
We also fix distrubtions to the noise terms,

\[
\begin{split}
\boldsymbol{\mathbf{\epsilon}}_t \sim \mathcal N(0,\Sigma_\epsilon),\\
\boldsymbol{\mathbf{\eta}}_t \sim \mathcal N(0,\Sigma_\eta),
\end{split}
\]

which are independant in time.

As in, for example, (Wikle and Cressie 1999), this is now in a
traditional enough form that the Kalman filter can be applied to fiter
and compute many necessary quantities for inference. We can use these
quantities in either an EM algorithm or a Bayesian approach. Firstly, we
cover the EM algorithm applied to this system.

At most, the parameters to be estimated are

\[
\begin{split}
\boldsymbol{\mathbf{\theta }}= \left(\boldsymbol{\mathbf{\theta}}_\kappa^\intercal, \boldsymbol{\mathbf{\beta}}^\intercal, \boldsymbol{\mathbf{m}}_0^\intercal, \mathrm{vec}[\Sigma_\epsilon]^\intercal, \mathrm{vec}[\Sigma_\eta]^\intercal, \mathrm{vec}[\Sigma_0]\right),
\end{split}
\]

where the \(\mathrm{vec}[\cdot]\) operator gives the elements of the
matrix in a column vector. Of course, in practice, some of these may be
estimated outside of the algorithm, fixed, given a much simpler form
(e.g.~\(\Sigma_\eta = \sigma_\eta^2 I_d\)), etc.

The E step of the EM algorithm relies on the quantity

\begin{equation}\phantomsection\label{eq-Qdef}{
\begin{split}
\mathcal Q(\boldsymbol{\mathbf{\theta}}; \boldsymbol{\mathbf{\theta}}') = \mathbb E_{\boldsymbol{\mathbf{Z}}_t\sim p(Z \mid \boldsymbol{\mathbf{\alpha}}_t,\boldsymbol{\mathbf{\theta}})}[\log p_{\boldsymbol{\mathbf{\theta}}}(\{\boldsymbol{\mathbf{Z}}_t\}_{t=0,\dots,T}, \{\boldsymbol{\mathbf{\alpha}}_t\}_{t=0,\dots,T})\mid\{\boldsymbol{\mathbf{Z}}_t\}_{t=0,\dots,T}],
\end{split}
}\end{equation}

which approximates
\(\log p_\theta(\{\boldsymbol{\mathbf{Z}}_t\}, \{\boldsymbol{\mathbf{\alpha}}_t\})\).
Using our model hierarchy, we have

\[
\begin{split}
p_{\boldsymbol{\mathbf{\theta}}}(\{\boldsymbol{\mathbf{Z}}_t\}_{t=0,\dots,T}, \{\boldsymbol{\mathbf{\alpha}}_t\}_{t=0,\dots,T})\mid\{\boldsymbol{\mathbf{Z}}_t\}_{t=0,\dots,T}) &= p(\{\boldsymbol{\mathbf{Z}}_t\}_{t=0,\dots,T}\mid \{\boldsymbol{\mathbf{\alpha}}_t\}_{t=0,\dots,T}, \boldsymbol{\mathbf{\theta}})\\
&\times p(\{\boldsymbol{\mathbf{\alpha}}_t\}_{t=1,\dots,T} \mid \{\boldsymbol{\mathbf{\alpha}}_{t-1}\}_{t=1,\dots,T}, \boldsymbol{\mathbf{\theta}})\\
&\times p(\alpha_0\mid \boldsymbol{\mathbf{\theta}}).
\end{split}
\]

{{[}NOTE: Let's improve the notation here, the subscript t's here is
bothering me{]}}

We will tackle each of these terms individually. Firstly, for the data
generating term, we have (ignoring additive constants)

\[
\begin{split}
&-2\log p(\{\boldsymbol{\mathbf{Z}}(t)\}_{t=0,\dots,T}\mid \{\boldsymbol{\mathbf{\alpha}}(t)\}_{t=0,\dots,T}, \boldsymbol{\mathbf{\theta}})\\ 
&= \sum_{t=0}^T \left(\boldsymbol{\mathbf{Z}}(t) - \Phi\boldsymbol{\mathbf{\alpha}}(t) - X\boldsymbol{\mathbf{\beta}})^\intercal \Sigma_\epsilon^{-1}(\boldsymbol{\mathbf{Z}}(t) - \Phi\boldsymbol{\mathbf{\alpha}}(t) - X\boldsymbol{\mathbf{\beta}}\right)\\
&=\mathrm{tr}(\Sigma_\epsilon^{-1}\{\left[\sum_{t=0}^T\boldsymbol{\mathbf{Z}}(t)\boldsymbol{\mathbf{Z}}(t)^\intercal\right] - 2\Phi\left[\sum_{t=0}^T\boldsymbol{\mathbf{\alpha}}(t)\boldsymbol{\mathbf{Z}}(t)^\intercal\right]\\
&\quad\quad - 2X\boldsymbol{\mathbf{\beta}}\sum_{t=0}^T \boldsymbol{\mathbf{Z}}(t)^\intercal + \Phi\left[\sum_{t=0}^T \boldsymbol{\mathbf{\alpha}}(t)\boldsymbol{\mathbf{\alpha}}(t)^\intercal\right]\Phi^\intercal\\
&\quad\quad + 2X\beta\Phi\sum_{t=0}^T\boldsymbol{\mathbf{\alpha}}(t) + (T+1)X\boldsymbol{\mathbf{\beta}}\boldsymbol{\mathbf{\beta}}^\intercal X^\intercal\}).
\end{split}
\]

{{[}NOTE: Yes, the formatting of this bothers me greatly. I'm also
pretty sure I've mucked up what should be \(z_t\) and \(Z_t\) around
here. Also, \(X\) is data as well; it should strictly be in some of the
conditinoing above, namely is Equation~\ref{eq-Qdef}. And should X be
time varying?{]}}

For the process terms,

\[
\begin{split}
&-2\log p(\{\boldsymbol{\mathbf{\alpha}}(t)\}_{t=1,\dots,T}\mid \{\boldsymbol{\mathbf{\alpha}}(t-1)\}_{t=1,\dots,T}, \boldsymbol{\mathbf{\theta}})\\ 
&=\sum_{t=1}^T (\boldsymbol{\mathbf{\alpha}}(t) - M(\boldsymbol{\mathbf{\theta}}_\kappa)\alpha(t-1))^\intercal\Sigma_\eta^{-1}(\boldsymbol{\mathbf{\alpha}}(t) - M(\boldsymbol{\mathbf{\theta}}_\kappa)\alpha(t-1))\\
&= \mathrm{tr}(\Sigma_\eta^{-1}\{\left[\sum_{t=1}^T\boldsymbol{\mathbf{\alpha}}(t)\boldsymbol{\mathbf{\alpha}}(t)^\intercal\right] - 2M(\boldsymbol{\mathbf{\theta}}_\kappa) \left[\sum_{t=1}^T\boldsymbol{\mathbf{\alpha}}(t-1)\boldsymbol{\mathbf{\alpha}}(t)^\intercal\right] \\
&\quad\quad +M(\boldsymbol{\mathbf{\theta}}_\kappa)^\intercal M(\boldsymbol{\mathbf{\theta}}_\kappa)\left[\sum_{t=1}^T\boldsymbol{\mathbf{\alpha}}(t-1)\boldsymbol{\mathbf{\alpha}}(t-1)^\intercal\right]\}),\\
\end{split}
\]

and

\[
\begin{split}
&-2\log p(\boldsymbol{\mathbf{\alpha}}(0)\mid\boldsymbol{\mathbf{\theta}})\\
&= (\boldsymbol{\mathbf{\alpha}}_0 - \boldsymbol{\mathbf{m}}_0)^\intercal \Sigma_0^{-1} (\boldsymbol{\mathbf{\alpha}}_0 - \boldsymbol{\mathbf{m}}_0)
&= \mathrm{tr}(\Sigma_0^{-1}\{\boldsymbol{\mathbf{\alpha}}_0\boldsymbol{\mathbf{\alpha}}_0^\intercal\} - 2\boldsymbol{\mathbf{\alpha}}_0\boldsymbol{\mathbf{m}}_0^\intercal + \boldsymbol{\mathbf{m}}_0\boldsymbol{\mathbf{m}}_0^\intercal)
\end{split}
\]

Taking the expectation and summing, giving names to some relevant
quantities,

\begin{split}
\mathcal Q(\boldsymbol{\mathbf{\theta}};\boldsymbol{\mathbf{\theta}}') &= \mathbb E_{Z\sim p(Z \mid \alpha,\boldsymbol{\mathbf{\theta}}')}[\log p_{\boldsymbol{\mathbf{\theta}}}(Z, \alpha(t)\mid Z = z]\\

&= \mathrm{tr}(\Sigma_\epsilon^{-1}\{\Xi^{(z)} - 2\Phi\Xi^{(\alpha,z)}- 2X\boldsymbol{\mathbf{\beta}}\xi^{(z)\intercal} + \Phi\Xi^{(\alpha)}\Phi^\intercal\\
&\quad\quad\quad\quad\quad + 2X\beta\Phi\xi^{(\alpha)} + (T+1)X\boldsymbol{\mathbf{\beta}}\boldsymbol{\mathbf{\beta}}^\intercal X^\intercal\})\\

&\quad\quad+\mathrm{tr}(\Sigma_\eta^{-1}\{(\Xi^{(\alpha)} - \boldsymbol{\mathbf{\alpha}}_0\boldsymbol{\mathbf{\alpha}}_0^\intercal) - 2M(\boldsymbol{\mathbf{\theta}}_\kappa) \boldsymbol{\mathbf{\alpha}}(t-1)\boldsymbol{\mathbf{\alpha}}(t)^\intercal \\
&\quad\quad\quad\quad\quad\quad +M(\boldsymbol{\mathbf{\theta}}_\kappa)^\intercal M(\boldsymbol{\mathbf{\theta}}_\kappa)\Xi^{(\alpha,-1)}\})\\

&\quad\quad+ \mathrm{tr}(\Sigma_0^{-1}\{\boldsymbol{\mathbf{\alpha}}_0\boldsymbol{\mathbf{\alpha}}_0^\intercal\} - 2\boldsymbol{\mathbf{\alpha}}_0\boldsymbol{\mathbf{m}}_0^\intercal + \boldsymbol{\mathbf{m}}_0\boldsymbol{\mathbf{m}}_0^\intercal)
\end{split}

where

\[
\begin{split}
\xi^{(z)} &:= \sum_{t=0}^T \boldsymbol{\mathbf{z}}(t)\\
\xi^{(\alpha)} &:= \mathbb{E}_{\boldsymbol{\mathbf{\theta}}'}[\sum_{t=0}^T\boldsymbol{\mathbf{\alpha}}(t)]\\
\Xi^{(z)} &:= \sum_{t=0}^T\boldsymbol{\mathbf{z}}(t)\boldsymbol{\mathbf{z}}(t)^\intercal\\
\Xi^{(\alpha,z)} &:= \mathbb{E}_{\boldsymbol{\mathbf{\theta}}'}[\sum_{t=0}^T\boldsymbol{\mathbf{\alpha}}(t)\boldsymbol{\mathbf{z}}(t)^\intercal]\\
\Xi^{(\alpha)} &:= \mathbb{E}_{\boldsymbol{\mathbf{\theta}}'}[\sum_{t=0}^T\boldsymbol{\mathbf{\alpha}}(t)\boldsymbol{\mathbf{\alpha}}(t)^\intercal]\\
\Xi^{(\alpha,-1)} &:=\mathbb{E}_{\boldsymbol{\mathbf{\theta}}'}[\sum_{t=1}^T\boldsymbol{\mathbf{\alpha}}(t-1)\boldsymbol{\mathbf{\alpha}}(t)^\intercal]
\end{split}
\]

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-cressie2015statistics}
Cressie, Noel, and Christopher K Wikle. 2015. \emph{Statistics for
Spatio-Temporal Data}. John Wiley \& Sons.

\bibitem[\citeproctext]{ref-dewar2008data}
Dewar, Michael, Kenneth Scerri, and Visakan Kadirkamanathan. 2008.
{``Data-Driven Spatio-Temporal Modeling Using the Integro-Difference
Equation.''} \emph{IEEE Transactions on Signal Processing} 57 (1):
83--91.

\bibitem[\citeproctext]{ref-wikle1999dimension}
Wikle, Christopher K, and Noel Cressie. 1999. {``A Dimension-Reduced
Approach to Space-Time Kalman Filtering.''} \emph{Biometrika} 86 (4):
815--29.

\bibitem[\citeproctext]{ref-zammit2022IDE}
Zammit-Mangion, Andrew. 2022. \emph{IDE: Integro-Difference Equation
Spatio-Temporal Models}. \url{https://CRAN.R-project.org/package=IDE}.

\end{CSLReferences}




\end{document}

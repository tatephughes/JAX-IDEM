#+TITLE: Integro-Difference Equation Model
#+AUTHOR: Evan Tate Paterson Hughes

:BOILERPLATE:
#+BIBLIOGRAPHY: Bibliography.bib
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [letterpaper]
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amsthm,amssymb,bm,bbm,tikz,tkz-graph, graphicx, subcaption, mathtools, algpseudocode}
#+LATEX_HEADER: \usepackage[cache=false]{minted}
#+LATEX_HEADER: \usetikzlibrary{arrows}
#+LATEX_HEADER: \usetikzlibrary{bayesnet}
#+LATEX_HEADER: \usetikzlibrary{matrix}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{corollary}[theorem]{Corollary}
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \newtheorem*{remark}{Remark}
#+LATEX_HEADER: \DeclareMathOperator{\E}{\mathbb E}
#+LATEX_HEADER: \DeclareMathOperator{\prob}{\mathbb P}
#+LATEX_HEADER: \DeclareMathOperator{\var}{\mathbb V\mathrm{ar}}
#+LATEX_HEADER: \DeclareMathOperator{\cov}{\mathbb C\mathrm{ov}}
#+LATEX_HEADER: \DeclareMathOperator{\cor}{\mathbb C\mathrm{or}}
#+LATEX_HEADER: \DeclareMathOperator{\normal}{\mathcal N}
#+LATEX_HEADER: \DeclareMathOperator{\invgam}{\mathcal{IG}}
#+LATEX_HEADER: \newcommand*{\mat}[1]{\bm{#1}}
#+LATEX_HEADER: \newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
#+LATEX_HEADER: \renewcommand*{\vec}[1]{\boldsymbol{\mathbf{#1}}}
#+EXPORT_EXCLUDE_TAGS: noexport
:END:

---------------------------------

[VERY UNFINISHED. PLEASE IGNORE.]

---------------------------------

* Introduction

As common and widespread as the problem is, spatio-temporal modelling still presents a great deal of difficulty. Inherently, Spatio-Temporal datasets are almost always high-dimensional, and repeated observations are usually not possible.

Traditionally, a descriptive approach has been made to model such systems.

We now have the tools to deal with dynamical models like \eqref{eq:linearprocess}, and so we return to the Integro-Difference Equation model; with the data model included,
\begin{align}
\begin{split}
Z(\vec s;t) &= Y(\vec s;t) + \epsilon_t(\vec s)\\
Y(\vec s;t+1) &= \int_{\mathcal D_s} \kappa(s,r;t) Y(r;t) d\vec r + \eta_t(\vec s).\label{eq:IDeq2}
\end{split}
\end{align}
Where $\eta_t(\vec s)$ is a small scale variation with no temporal dynamics.
Again, to make this clear, $t$ is put as a subscript rather than as an argument, to make clear that although this value changes with time, that change has no dynamical structure and is independent in time.
Cressie and Wikle call this a `spatially descriptive' component.
Usually, the `weight function' $m$ is called the /kernel/.
While I have written \eqref{eq:IDeq2} to be as general as possible, the kernel is usually simplified.
Often it is /homogeneous/, depending only on the difference vector of the two spatial points and not on time, $\kappa(\vec s-\vec r)$; isotropic, depending only on the magnitude of the distance, $\kappa(\Vert \vec s - \vec r\Vert;t)$; not dependant only on time, $\kappa(\vec s,\vec r)$; or dependant on time only through a parameter $\vec\theta_t$, $\kappa(\vec s,\vec r;\vec\theta_t)$.
Homogeneity (at least in space) is often beneficial as it reveals a `convolutional' form of \eqref{eq:IDeq2}, where $Y(\vec s;t)$ is the convolution of $Y(\vec s;t-1)$ against the kernel $\kappa(\vec s;t)$, plus some small scale variation $\eta$;
\begin{align}
Y(\vec s;t+1) = \int_{\mathcal D_s} \kappa(s-r;t) Y(r;t) d\vec r + \eta_t(\vec s). \label{eq:IDeqconv}
\end{align}

This seems like a reasonable model for the process's diffusion and advection in a spatially continuous way.
Each state is a continuous weighted integral (sum) of the previous state.
The form of $\kappa$ allows us to make use of some of the dynamics of the system; in many geological settings we most likely follow Tobler's law in some sense to model diffusion, with weights depending of the direction of $\vec s-\vec r$ giving us advection, or movement, of the process.
At first glance, this looks wholly distinct from \eqref{eq:linearprocess}, but in fact, it can be reduced to being effectively the same problem, which we shall show shortly.

Further, we assume that $\epsilon_t(\vec s)$ and $\nu_t(\vec s)$ are uncorrelated with each other (and, again, uncorrelated in time).

We decompose the process and the kernel as follows [cite:roughly following @dewar2008data];
\begin{align}
\kappa(\vec s, \vec r;t) &= \sum_i\alpha_{i,t}\psi_i(\vec s, \vec r),\label{eq:mexpan}\\
Y(s;t) &= \sum_j \beta_{j,t}\phi_j(\vec s), \label{eq:Yexpan}
\end{align}
where $\{\psi_i\}_{i\in\mathbb N}$ and $\{\phi_j\}_{j\in\mathbb N}$ are complete, linearly independent sets of basis functions.
If we have a homogeneous kernel [cite:as in @wikle1999dimension], we could use the same set of basis functions for the expansion of $m$ and $Y$. $\alpha_{i,t}$ and $\beta_{i,t}$ are unknown sequences.

We assume that \eqref{eq:mexpan} and \eqref{eq:Yexpan} can be decomposed into $I$ and $J$ dominant components respectively, and truncate these sums and write them in vector form;
\begin{align}
m(\vec s, \vec r;t) &\approx m_I(\vec s, \vec r;t) = \sum_{i=1}^I \alpha_{i,t}\psi_i(\vec s,r) = \vec\psi_I(\vec s, \vec r)^{\intercal} \vec\alpha_{t,I},\\
Y(\vec s;t) &\approx Y_J(\vec s) = \sum_j^J \beta_{j,t}\phi_j(\vec s) = \vec\phi_J(\vec s)^{\intercal} \vec\beta_{t, J},
\end{align}
where $\vec \psi_I(\vec s,\vec r) = (\psi_1(\vec s, \vec r),\dots, \psi_I(\vec s,\vec r))^{\intercal}$ and $\vec \phi_J(\vec s) = (\phi_1(\vec s), \dots, \phi_J(\vec s))^{\intercal}$. For brevity, we write $m = m_I$ and $Y = Y_J$ in the following.

#+ATTR_LATEX: :options [Adapted from Dewar et al., 2008]
#+begin_lemma
\label{lem:variation}
We assume that the small-scale variation $\vec \nu_t(\vec s)$ in \eqref{eq:IDeq2} is Gaussian with zero mean and covariance defined by
\begin{align}
\cov[\nu_t(\vec s), \nu_{t+\tau}(\vec r)] =- \begin{cases*}
\sigma^2\delta(\vec s - \vec r) & if $\tau=0$\\
0 & else.
\end{cases*}
\end{align}
Then, the integral
\begin{align}
\vec \omega_t = \int_{\mathcal D_s} \vec \phi(\vec s)\nu_t(\vec s)d\vec s\label{eq:omega}
\end{align}
is also Gaussian with zero mean and covariance
\begin{align*}
\cov[\vec \omega_t] = \sigma^2\int_{\mathcal D_s} \vec \phi(\vec s) \vec \phi(\vec s)^{\intercal}d\vec s \quad \forall t\in\mathbb N.
\end{align*}
#+end_lemma
#+begin_proof
We have that \eqref{eq:omega} is a linear combination of Gaussian $\nu_t(\vec s)$, therefore it is itself Gaussian.
Showing the two moments is then easy. With expectations and covariances taken with respect to time, 
\begin{align*}
\E[\vec \omega_t] &= \E \left[ \int_{\mathcal D_s} \vec \phi(\vec s) \omega_t(\vec s) d\vec s \right] = \int_{\mathcal D_s} \vec \phi(\vec s) \E[\omega_t(\vec s)] d\vec s = 0\\
\cov[\vec \omega_t] &= \E[\omega_t\omega_t^{\intercal}] - \E[\omega_t]E[\omega_t]^{\intercal} = \E[\omega_t\omega_t^{\intercal}]\\
&= \E \left[ \int_{\mathcal D_s} \vec \phi(\vec s) \nu_t(\vec s) d\vec s \int_{\mathcal D_s} \vec \phi(\vec r)^{\intercal} \nu_t(\vec r) d \vec r \right] = \int_{\mathcal D_s^2} \vec \phi(\vec s) \vec \phi(\vec r)^{\intercal} \E[\nu_t(\vec s)\nu_t(\vec r)]d\vec s d\vec r\\
&= \int_{\mathcal D_s^2} \vec \phi(\vec s) \vec \phi(\vec r)^{\intercal} \sigma^2\delta(\vec s-\vec r) d\vec s d\vec r = \sigma^2 \int_{\mathcal D_s} \vec \phi(\vec s)\vec \phi(\vec s)^{\intercal} d\vec s.
\end{align*}
#+end_proof


Continuing to follow Dewar et al. with some generalisation, we define the following matrices;
\begin{align}
\mat\Phi (\vec s) &= \int_{\mathcal D_s} \vec\psi(\vec s,\vec r) \vec\phi(r)^{\intercal}d\vec r &\in \mathcal M_{I\times J}[\mathbb R]\\
\mat\Psi^{(Z)} &= \int_{\mathcal D_s} \vec \phi(\vec s)\vec \phi(\vec s)^{\intercal} d\vec s &\in \mathbb M_{I\times I}[\mathbb R]\\
\mat\Psi^{(\alpha)}_t &= \int_{\mathcal D_s} \vec \phi(\vec s)\vec \alpha_t^{\intercal} \mat \Phi(\vec s) d\vec s &\in \mathbb M_{I\times I}[\mathbb R].
\end{align}
Using these, we can finally return to a familiar state-space form.

#+ATTR_LATEX: :options [Adapted from Dewar et al., 2008]
#+begin_theorem
\label{thm:idtoss}
We have that $\vec \beta(t)$ evolves by the state-space equation
\begin{align}
\vec \beta(t+1) = \mat M_t \vec \beta(t) + \vec \eta_t,\label{eq:idstatespace}
\end{align}
where $\eta_t$ is Gaussian with covariance $\sigma^2(\mat \Psi^{(Z)})^{-1}$, and $\mat M_t = (\mat\Psi^{(Z)})^{-1}\mat\Psi^{(\alpha)}_t$.

Furthermore, we then recall that we assume (ignoring approximations) that $Y(\vec s;t) = \vec\phi(\vec s)^{\intercal}\vec\beta(t)$. So, fixing stations $\{\vec s_1,\dots, \vec s_n\}$ and setting $\mat X = [\vec\phi(\vec s_1), \dots, \vec \phi(\vec s_n)]^{\intercal}$, we return to a system of the form \eqref{eq:linearprocess}.
#+end_theorem
#+begin_proof
Expanding \eqref{eq:IDeq2} with \eqref{eq:Yexpan} and \eqref{eq:mexpan},
\begin{align*}
Y(\vec s; t+1) &= \vec\phi(\vec s)^{\intercal}\vec\beta_(t+1) = \int_{\mathcal D_s} \vec\psi(\vec s,\vec r)^{\intercal}\vec \alpha_t\vec \phi(\vec s)^{\intercal}\vec\beta(t)d\vec r + \nu_t(\vec s),\\
&= \vec\alpha_t^{\intercal} \int_{\mathcal D_s} \vec\psi(\vec s,\vec r)\vec\phi(\vec s)d\vec r \vec\beta(t) + \nu_t(\vec s),\\
&= \vec\alpha_t^{\intercal} \mat\Phi(\vec s)\vec\beta(t) + \nu_t(\vec s).
\end{align*}
Now we multiply the left hand side by $\vec\phi(\vec s)$ and integrate over $\vec s$,
\begin{align*}
&\quad \int_{\mathcal D_s} \vec\phi(\vec s)\vec\phi(\vec s)^{\intercal}d\vec s\vec\beta(t+1) = \int_{\mathcal D_s}\vec \phi(\vec s)\vec\alpha_t^{\intercal}\mat\Phi(\vec s)d\vec s\vec\beta(t) + \int_{\mathcal D_s} \vec\phi(\vec s)\vec\nu_t(\vec s)d \vec s,\\
&= \mat\Psi^{(Z)}\vec\beta(t+1) = \mat\Psi^{(\alpha)}_t \vec\beta(t) + \vec\omega_t,
\end{align*}
where we used Lemma \ref{lem:variation}.
We then arrive at \eqref{eq:idstatespace} by multiplying the left hand sides by $(\mat\Psi^{(Z)})^{-1}$, writing $\vec\eta_t:= (\mat\Psi^{(Z)})^{-1}\vec\omega_t$.
Finding the covariance of $\vec\eta_t$ follows directly from Lemma \ref{lem:variation}.

Once the stations are fixed, we can write $\vec Y(t) = (Y(\vec s_1;t), \dots, Y(\vec s_n;t))$ and $\vec Z(t) = (Z(\vec s_1;t), \dots, Z(\vec s_n;t))$, then we get a system of the form \eqref{eq:linearprocess}.
#+end_proof



Currently, the Kalman filter, the Information filter, the Square-root filter, and the square-root-information filter are all implemented.

We will use a simulated data set, from cosine basis functions over 100 frequencies and invariant kernel.
See figure (?) for the 6 time points of the simulated process.

We then filter this data, and time the implemented filters to compute the marginal log likelihood.
We run the alogrithms with a sequence of model parameters that are close to the ones used to simulate the data, with added noise to avoid the memoisation the JAX uses.

We simulate $n=300$ observations per time point in total, and redact observations in order to show the compute times for each $n$ between 50 and 300.
These are computed in 64 bit for stability, and the results are in figure (?)

Additionally, to demonstrate the square root filters stability, we also fix $n$ and progressively increase $n$.
The data is simulated from a high-dimensional process basis, and then filtered using models with a lower $r$, increasing in square between $5^2$ and $15^2$.
The results are shown in figure (?).

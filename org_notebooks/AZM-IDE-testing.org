
#+TITLE: Testing the R package

:BOILERPLATE:
#+BIBLIOGRAPHY: Bibliography.bib
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [letterpaper]
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amsthm,amssymb,bm,bbm,tikz,tkz-graph, graphicx, subcaption, mathtools, algpseudocode}
#+LATEX_HEADER: \usepackage[cache=false]{minted}
#+LATEX_HEADER: \usetikzlibrary{arrows}
#+LATEX_HEADER: \usetikzlibrary{bayesnet}
#+LATEX_HEADER: \usetikzlibrary{matrix}
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \newtheorem{theorem}{Theorem}[section]
#+LATEX_HEADER: \newtheorem{corollary}[theorem]{Corollary}
#+LATEX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
#+LATEX_HEADER: \newtheorem{definition}[theorem]{Definition}
#+LATEX_HEADER: \newtheorem*{remark}{Remark}
#+LATEX_HEADER: \DeclareMathOperator{\E}{\mathbb E}
#+LATEX_HEADER: \DeclareMathOperator{\prob}{\mathbb P}
#+LATEX_HEADER: \DeclareMathOperator{\var}{\mathbb V\mathrm{ar}}
#+LATEX_HEADER: \DeclareMathOperator{\cov}{\mathbb C\mathrm{ov}}
#+LATEX_HEADER: \DeclareMathOperator{\cor}{\mathbb C\mathrm{or}}
#+LATEX_HEADER: \DeclareMathOperator{\normal}{\mathcal N}
#+LATEX_HEADER: \DeclareMathOperator{\invgam}{\mathcal{IG}}
#+LATEX_HEADER: \newcommand*{\mat}[1]{\bm{#1}}
#+LATEX_HEADER: \newcommand{\norm}[1]{\left\Vert #1 \right\Vert}
#+LATEX_HEADER: \renewcommand*{\vec}[1]{\boldsymbol{\mathbf{#1}}}
#+EXPORT_EXCLUDE_TAGS: noexport
:END:

We follow the 'spatio-temporal statistics in R' book, Lab 5.2., covering Andrew Zammit-Mangion's R implementation of the IDE model.

* Imports

#+begin_src R :session example :results none
library("plyr")
library("dplyr")
library("IDE")
library("FRK")
library("ggplot2")
library("sp")
library("spacetime")
library("STRbook")
#+end_src

* Basic Testing

The IDE package comes with a pre-defined model. ~SIMIDE~ also allows for a custom model to be placed as the argument ~IDEmodel~, but without it, there is a default

#+begin_src R :session example :results none
SIM1 <- simIDE(T=10, nobs=100, k_spat_invariant=1)
#+end_src

This function then completely ignores the argument ~nobs~ and creates a uniform grid across $[0,t]\times[0,1]$.

It then uses ~auto_basis~ from ~FRK~ to create a basis for Y. The documentation for this function is [[https://andrewzm.github.io/FRK/reference/auto_basis.html][here]].  The ZM code doesn't specify a basis type, although the book claims it uses bisquare. The default in FRK is, however, a vector containing all available types, so I'm not sure how that works. If I were to guess, it makes all of them? 

It would be ideal to implement a similar mechanism for basis funcitons in JAX, though it may also be worthwhile to look into what already exists. 
*************** TODO Do this thing :)
*************** END

The parameter ~regular=1~ implies that there is only one basis function at the coarsest resolution (meaning only three basis functions in total). This can't be right? Lets test it quickly

#+begin_src R :session example :results graphics file :file ./show_basis_test.png :height 200 :width 300 :exports both
zlocs <- data.frame(s1=runif(100), s2=runif(100))

Y_basis <- auto_basis(manifold = plane(),
                      data = SpatialPoints(zlocs),
                      regular = 1,
                      nres = 2)

show_basis(Y_basis)
#+end_src

#+RESULTS:
[[file:./show_basis_test.png]]

so no, there are 90 basis functions; 30 for the first resolution, 60 for the second. The documentation says

#+begin_quote
'with the smallest number of basis functions in each row or column equal to the value of regular in the coarsest resolution (note, this is just the smallest number of basis functions). Subsequent resolutions have twice the number of basis functions in each row or column.'
#+end_quote

This seems inaccurate, with there being three per locum in the first resolution and then triple (rather than double ) in the next resolution. This would be too hard to confirm I suppose, and is somewhat irrelevant.

#+begin_src R :session example :results output :exports both
print(nbasis(Y_basis))
#+end_src

#+RESULTS:
: [1] 90

Next, ~G_const~ is set at ~constant_basis~. Why? not really sure... There is a comment calling the 'kernel decomposition'. My guess is that there were plans to allow for basis-defined kernel functions (as described in Dewar et al 2009), but since the default is using the Gaussian-like parameterised kernel function, the 'basis' becomes simply a constant multiplier of said kernel function.



* Matching AZM's code

#+begin_src R :session example :results none
library("plyr")
library("dplyr")
library("IDE")
library("FRK")
library("ggplot2")
library("sp")
library("spacetime")
library("STRbook")
#+end_src

** ~construct_grid~ and ~construct_M~

#+begin_src R :session example :results none
construct_grid <- function(bbox, ngrid, coordnames = NULL) {
  ndim <- nrow(bbox)
  if(length(ngrid) == 1)
    ngrid <- rep(ngrid, ndim)
  if(!(length(ngrid) == ndim) | !is.numeric(ngrid))
    stop("ngrid needs to be a numeric (which will be rounded if not an integer)
         with length one or equal to the number of columns in bbox")
  ngrid <- round(ngrid)

  s <- lapply(1:nrow(bbox), function(i)
    seq(bbox[i,1], bbox[i,2], length.out = ngrid[i]))
  s_grid <- do.call("expand.grid", s)
  if(is.null(coordnames)) {
    names(s_grid) <- paste0("s",1:ndim)
  } else {
    names(s_grid) <- coordnames
  }
  list(s_grid_df = s_grid,
       s_grid_mat = s_grid %>% as.matrix(),
       ds = (bbox[,2] - bbox[,1])/(ngrid-1),
       area = prod((bbox[,2] - bbox[,1])/(ngrid-1)))
}

construct_M <- function(Y_basis, s) {
  PHI <- eval_basis(Y_basis, s$s_grid_mat)
  GRAM <- crossprod(PHI)*s$area
  GRAM_inv <- solve(GRAM)
  ndim <- dimensions(Y_basis)
  function(K_basis, ki) {
    K <- construct_kernel(K_basis, ki)
    Kmat <- K(s$s_grid_mat, s$s_grid_mat)
    M <- GRAM_inv %*% crossprod(t(Kmat) %*% PHI, PHI)*s$area^2
  }
}
#+end_src

*** 

#+begin_src R :session example :results none
T = 9
nobs = 100

set.seed(1)
zlocs <- data.frame(s1 = runif(100),
                    s2 = runif(100))

## Spatial decomposition
Y_basis <- auto_basis(manifold = plane(),
                      data = SpatialPoints(zlocs),
                      regular = 1,
                      nres = 2)
r <- nbasis(Y_basis)

## Kernel decomposition
G_const <- constant_basis()

## Regression coeffocients
beta <- c(0.2,0.2,0.2)

## Other parameters
sigma2_eta <- 0.01^2
sigma2_eps <- 0.01^2

## Spatial domain
bbox <- matrix(c(0,0,1,1),2,2)
s <- construct_grid(bbox, 41)
alpha <- matrix(0,r,T)

K_basis <- list(G_const, G_const, G_const, G_const)
k <- list(150, 0.002, -0.1, 0.1)
alpha[65,1] <- 1

library(Matrix)

Sigma_eta <- sigma2_eta * Diagonal(r)
Sigma_eps <- sigma2_eps * Diagonal(nobs * T)
Q_eta <- Sigma_eta %>% solve()
Q_eps <- Sigma_eps %>% solve()

Mfun <- construct_M(Y_basis, s)
M <- Mfun(K_basis, k)
#+end_src

#+begin_src R :session example :results none
repcol <- function(x,n){
  l <- lapply(1:n, function(i) x)
  y <- do.call("c", l)
  matrix(y, ncol = n, byrow = FALSE)
}

construct_kernel <- function(Basis, ki) {
  if(!is.list(Basis)) stop("Basis needs to be of class list")
  if(!all(sapply(Basis, function(x) is(x,"Basis"))))
    stop("All Basis functions need to be of class Basis")
  ndim <- dimensions(Basis[[1]])

  function(s, r) {
    if(1) { ## Actual basis
      theta_s <- list()
      for(i in 1:(2 + ndim)) {
        theta_s[[i]] <- (eval_basis(Basis[[i]], s) %*% ki[[i]]) %>%
          as.numeric() %>%
          repcol(nrow(r))
      }
      theta_s_1 <- lapply(theta_s, function(x) x[,1])
      D <- FRK::distR(s + do.call("cbind", theta_s_1[3:(2 + ndim)]), r)
      theta_s[[1]] * exp(-D^2/theta_s[[2]])
    } else {
      D <- FRK::distR(t(t(s) + c(ki[[3]], ki[[4]])), r)
      ki[[1]] * exp(-D^2/ki[[2]])
    }
  }
}

kernel <- construct_kernel(K_basis, k)

# Matches!
print(kernel(s$s_grid_mat, s$s_grid_mat)[1:5,1:5])

PHI <- eval_basis(Y_basis, s$s_grid_mat)

# quite different!
print(PHI[1:5,1:5])
#+end_src

#+begin_src R :session example :results none
library(FRK)
library(sp)
library(tidyverse)

zlocs <- data.frame(s1=runif(100), s2=runif(100))

m = plane()

data = SpatialPoints(zlocs)
coords <- coordinates(data)
regular = 1
nres = 2

xrange <- range(coords[,1])
yrange <- range(coords[,2])

if(is(m,"plane") & regular) {
  asp_ratio <- diff(yrange) / diff(xrange)
  if(asp_ratio < 1) {
    ny <- regular
    nx <- ny / asp_ratio
  } else {
    nx <- regular
    ny <- nx * asp_ratio
  }
}

i=1

xgrid <- seq(xrange[1], xrange[2], length = round(nx*(3^(i)))) # x coordinates of centroids
ygrid <- seq(yrange[1], yrange[2], length = round(ny*(3^(i)))) # y coordinates of centroids
this_res_locs <- xgrid %>%
  expand.grid(ygrid) %>%   # form the grid in long-table format
  as.matrix()              # convert to matrix


#+end_src
